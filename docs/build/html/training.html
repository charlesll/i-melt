<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Training &mdash; i-Melt 2.0.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=51b770b3"></script>
        <script src="_static/doctools.js?v=9a2dae69"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Predictions" href="predictions.html" />
    <link rel="prev" title="Database" href="data.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            i-Melt
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">Database</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#simple-example">Simple example</a></li>
<li class="toctree-l2"><a class="reference internal" href="#training-scripts">Training scripts</a></li>
<li class="toctree-l2"><a class="reference internal" href="#training-one-network">Training one network</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hyperparameter-tuning">Hyperparameter tuning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#ray-tune-optuna">RAY TUNE + OPTUNA</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#training-candidates">Training candidates</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="predictions.html">Predictions</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="bugs.html">Errors and bugs</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">i-Melt</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Training</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/training.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="training">
<h1>Training<a class="headerlink" href="#training" title="Link to this heading"></a></h1>
<p>The i-Melt 2.1 library is meant to provide trained models and use them for predictions.</p>
<p>However, if you want to play with the code and train new models, you can do so following the instructions listed below. Note that paths will probably have to be slightly modified, as the current library is intended to be used for predictions and the code for training has been written prior to the latest “production release”.</p>
<section id="simple-example">
<h2>Simple example<a class="headerlink" href="#simple-example" title="Link to this heading"></a></h2>
<p>The notebook <a class="reference external" href="https://github.com/charlesll/i-melt/blob/main/examples/Training_single.ipynb">Training_single.ipynb</a> provides a simple example of how you can train your own i-Melt neural networks.</p>
</section>
<section id="training-scripts">
<h2>Training scripts<a class="headerlink" href="#training-scripts" title="Link to this heading"></a></h2>
<p>Scripts for building, training models and providing useful functions are provided <a class="reference external" href="https://github.com/charlesll/i-melt/blob/master/src/">here</a>.</p>
<p>The easiest way of training one or multiple neural networks is to use those scripts. I suggest getting a copy of the Github repository and working in it directly, it will simplify things.</p>
</section>
<section id="training-one-network">
<h2>Training one network<a class="headerlink" href="#training-one-network" title="Link to this heading"></a></h2>
<p>The code <a class="reference external" href="https://github.com/charlesll/i-melt/blob/master/src/Training_single.py">Training_single.py</a> allows training only one network and playing with it. The following steps are performed.</p>
<p>After importing the libraries (see notebook), we load the data:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span> <span class="c1"># training on the GPU</span>

<span class="c1"># custom data loader, automatically sent to the GPU</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">imelt</span><span class="o">.</span><span class="n">data_loader</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>We select an architecture. For this example, we have selected the reference architecture from Le Losq et al. 2021:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nb_layers</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">nb_neurons</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">p_drop</span> <span class="o">=</span> <span class="mf">0.10</span> <span class="c1"># we increased dropout here as this now works well with GELU units</span>
</pre></div>
</div>
<p>If we want to save the model and figures in a directory such as <cite>./outputs/</cite>, we can use this code to check if the folder exists and create it if not:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">imelt</span><span class="o">.</span><span class="n">create_dir</span><span class="p">(</span><span class="s1">&#39;./outputs/&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Now we need a name for our model, we can generate it with the hyperparameters actually, this will help us having automatic names in case we try different architectures:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;./outputs/candidates/l&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">nb_layers</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot;_n&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">nb_neurons</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot;_p&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">p_drop</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot;_test&quot;</span><span class="o">+</span><span class="s2">&quot;.pth&quot;</span>
</pre></div>
</div>
<p>and we declare the model using <cite>imelt.model()</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">neuralmodel</span> <span class="o">=</span> <span class="n">imelt</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">ds</span><span class="o">.</span><span class="n">x_visco_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="c1"># input shape</span>
                                                <span class="n">hidden_size</span><span class="o">=</span><span class="n">nb_neurons</span><span class="p">,</span> <span class="c1"># number of neurons per hidden layer</span>
                                                <span class="n">num_layers</span><span class="o">=</span><span class="n">nb_layers</span><span class="p">,</span> <span class="c1"># number of hidden layers</span>
                                                <span class="n">nb_channels_raman</span><span class="o">=</span><span class="n">ds</span><span class="o">.</span><span class="n">nb_channels_raman</span><span class="p">,</span> <span class="c1"># number of input channels for Raman spectra</span>
                                                <span class="n">activation_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">(),</span> <span class="c1"># ANN activation function</span>
                                                <span class="n">p_drop</span><span class="o">=</span><span class="n">p_drop</span> <span class="c1"># dropout probability</span>
                                                <span class="p">)</span>
</pre></div>
</div>
<p>We select a criterion for training (the MSE criterion from PyTorch) and send it to the GPU device</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="n">criterion</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1"># sending criterion on device</span>
</pre></div>
</div>
<p>Before training, we need to initilize the bias layer using the model <cite>output_bias_init</cite> method, and we send the network parameters to the GPU:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">neuralmodel</span><span class="o">.</span><span class="n">output_bias_init</span><span class="p">()</span>
<span class="n">neuralmodel</span> <span class="o">=</span> <span class="n">neuralmodel</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="c1"># this is just to make sure we are using always float() numbers</span>
<span class="n">neuralmodel</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>Training will be done with the <a class="reference external" href="https://arxiv.org/abs/1412.6980">ADAM</a> optimizer with a tuned learning rate of 0.0003:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">neuralmodel</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.0003</span><span class="p">)</span>
</pre></div>
</div>
<p>We have build a function for training in the imelt library that performs early stopping. You have to select:</p>
<ul class="simple">
<li><p>the patience (how much epoch do you wait once you notice the validation error stops improving).</p></li>
<li><p>the min_delta variable, which represents the sensitivity to determine if the RMSE on the validation dataset really improved or not.</p></li>
</ul>
<p>The <cite>imelt.training()</cite> function outputs the trained model, and records of the training and validation losses during the epochs.</p>
<p>Training can thus be done with this code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">neuralmodel</span><span class="p">,</span> <span class="n">record_train_loss</span><span class="p">,</span> <span class="n">record_valid_loss</span> <span class="o">=</span> <span class="n">imelt</span><span class="o">.</span><span class="n">training</span><span class="p">(</span><span class="n">neuralmodel</span><span class="p">,</span> <span class="c1"># model</span>
                                                           <span class="n">ds</span><span class="p">,</span> <span class="c1"># dataset</span>
                                                           <span class="n">criterion</span><span class="p">,</span> <span class="c1"># criterion for training (RMSE here)</span>
                                                           <span class="n">optimizer</span><span class="p">,</span> <span class="c1"># optimizer: ADAM</span>
                                                           <span class="n">save_switch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># do we save the best models?</span>
                                                           <span class="n">save_name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="c1"># where do we save them?</span>
                                                           <span class="n">train_patience</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="c1"># how many epochs we wait until early stopping?</span>
                                                           <span class="n">min_delta</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="c1"># how sensitive should we be to consider the validation metric has improved?</span>
                                                           <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span> <span class="c1"># do you want text?</span>
                                                           <span class="p">)</span>
</pre></div>
</div>
</section>
<section id="hyperparameter-tuning">
<h2>Hyperparameter tuning<a class="headerlink" href="#hyperparameter-tuning" title="Link to this heading"></a></h2>
<section id="ray-tune-optuna">
<h3>RAY TUNE + OPTUNA<a class="headerlink" href="#ray-tune-optuna" title="Link to this heading"></a></h3>
<p>In the version 2.0 and above, we rely on <a class="reference external" href="https://docs.ray.io/en/latest/tune/index.html">Ray Tune</a> and <a class="reference external" href="https://optuna.org/">Optuna</a> to search for the best models.</p>
<p>The script <a class="reference external" href="https://github.com/charlesll/i-melt/blob/master/src/ray_opt.py">ray_opt.py</a> allows running a Ray Tune experiment.</p>
<p>The script <a class="reference external" href="https://github.com/charlesll/i-melt/blob/master/src/ray_select.py">ray_select.py</a> allows selecting the best models
based on posterior analysis of the Ray Tune experiment (all metrics recorded in an Excel spreadsheet that must be provided for model selection).</p>
</section>
</section>
<section id="training-candidates">
<h2>Training candidates<a class="headerlink" href="#training-candidates" title="Link to this heading"></a></h2>
<p><strong>Note : this was used in v1.2 for model selection, but now we rely on the Ray Tune + Optuna run to select models.</strong></p>
<p>In any case, this still works. The code <a class="reference external" href="https://github.com/charlesll/i-melt/blob/master/Training_candidates.py">Training_Candidates.py</a> allows training 100 networks with a given architecture and selects the 10 best ones, which are saved in ./model/best/ and used for future predictions.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="data.html" class="btn btn-neutral float-left" title="Database" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="predictions.html" class="btn btn-neutral float-right" title="Predictions" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021-2024, Charles Le Losq, Barbara Baldoni, Andrew P. Valentine.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>